{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv QML Curation Demo\n",
    "\n",
    "This notebook demonstrates how to use the `arxivqml` package to search for and curate papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import the main job runner and the database query functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arxivqml.main import run_arxiv_search_job\n",
    "from arxivqml.database import get_db_collection, get_top_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run the Full Curation Job\n",
    "\n",
    "The following function will connect to the database and LLM, search for new papers across all configured categories, curate them, and save the results to MongoDB.\n",
    "\n",
    "**Note:** Make sure your `.env` file is configured with `MONGO_URI` and `GEMINI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to run the full job\n",
    "# run_arxiv_search_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Full Curation Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting new arXiv search job at 2025-09-30 23:12:28.802410 ---\n",
      "✓ Successfully connected to MongoDB: arxiv_research.qml_papers\n",
      "✓ LLM initialized: models/gemini-2.0-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759288348.832886 4116830 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from arxivqml import config\n",
    "from arxivqml import database\n",
    "from arxivqml import arxiv_search\n",
    "from arxivqml import curation\n",
    "\n",
    "print(f\"\\n--- Starting new arXiv search job at {datetime.now()} ---\")\n",
    "# 1. Initialize connections\n",
    "collection = database.get_db_collection()\n",
    "llm = curation.get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing arXiv search in 'quant-ph' for query: 'ti:\"Quantum Machine Learning\" OR abs:\"Quantum Machine Learni...'\n",
      "Found 25 new papers.\n",
      "Scored 'Quantum Annealing for Minimum Bisection Problem: A Machine L...' -> 7/10\n",
      "Scored 'QUBO-based training for VQAs on Quantum Annealers...' -> 7/10\n",
      "Scored 'Investigation of D-Wave quantum annealing for training Restr...' -> 6/10\n",
      "Scored 'Comparison of D-Wave Quantum Annealing and Markov Chain Mont...' -> 6/10\n",
      "Scored 'Minor Embedding for Quantum Annealing with Reinforcement Lea...' -> 7/10\n",
      "Scored 'Quantum Annealing for Machine Learning: Applications in Feat...' -> 7/10\n",
      "Scored 'Quantum Annealing Algorithms for Estimating Ising Partition ...' -> 6/10\n",
      "Scored 'A quantum annealing approach to graph node embedding...' -> 8/10\n",
      "Scored 'Hyperspectral image segmentation with a machine learning mod...' -> 7/10\n",
      "Scored 'Quantum Annealing Feature Selection on Light-weight Medical ...' -> 7/10\n",
      "Scored 'Black-box optimization and quantum annealing for filtering o...' -> 7/10\n",
      "Scored 'Quantum Annealing for Robust Principal Component Analysis...' -> 7/10\n",
      "Scored 'Transfer Learning for Deep-Unfolded Combinatorial Optimizati...' -> 7/10\n",
      "Scored 'QAHAN: A Quantum Annealing Hard Attention Network...' -> 8/10\n",
      "Scored 'Quantum Annealing based Feature Selection in Machine Learnin...' -> 7/10\n",
      "Scored 'Analyzing the Effectiveness of Quantum Annealing with Meta-L...' -> 6/10\n",
      "Scored 'Protein Design by Integrating Machine Learning with Quantum ...' -> 6/10\n",
      "Scored 'Local Binary and Multiclass SVMs Trained on a Quantum Anneal...' -> 8/10\n",
      "Scored 'Association between Prefrontal fNIRS signals during Cognitiv...' -> 6/10\n",
      "Scored 'ILP-based Resource Optimization Realized by Quantum Annealin...' -> 7/10\n",
      "Scored 'FPGA-Placement via Quantum Annealing...' -> 7/10\n",
      "Scored 'Nonnegative/Binary Matrix Factorization for Image Classifica...' -> 7/10\n",
      "Scored 'Projected Stochastic Gradient Descent with Quantum Annealed ...' -> 8/10\n",
      "Scored 'Investigation of factors regarding the effects of COVID-19 p...' -> 7/10\n",
      "Scored 'Neural Networks for Programming Quantum Annealers...' -> 6/10\n"
     ]
    }
   ],
   "source": [
    "category = config.CATEGORIES[0]\n",
    "\n",
    "# Step 2a: Search arXiv for new papers\n",
    "new_papers = arxiv_search.search_arxiv(\n",
    "    category=category, \n",
    "    query=config.QUERY_STRING, \n",
    "    collection=collection\n",
    ")\n",
    "\n",
    "# Step 2b: Curate and score papers with LLM\n",
    "curated_papers = curation.curate_papers(\n",
    "    papers=new_papers, \n",
    "    guidance_context=config.GUIDANCE_CONTEXT, \n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2c: Insert curated papers into the database\n",
    "if curated_papers:\n",
    "    database.insert_papers(collection, curated_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Loop through categories and process papers\n",
    "for category in config.CATEGORIES:\n",
    "    print(f\"\\n--- Processing category: {category} ---\")\n",
    "\n",
    "    # Step 2a: Search arXiv for new papers\n",
    "    new_papers = arxiv_search.search_arxiv(\n",
    "        category=category, \n",
    "        query=config.QUERY_STRING, \n",
    "        collection=collection\n",
    "    )\n",
    "\n",
    "    if not new_papers:\n",
    "        print(f\"No new papers found for category '{category}'.\")\n",
    "        continue\n",
    "\n",
    "    # Step 2b: Curate and score papers with LLM\n",
    "    curated_papers = curation.curate_papers(\n",
    "        papers=new_papers, \n",
    "        guidance_context=config.GUIDANCE_CONTEXT, \n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Step 2c: Insert curated papers into the database\n",
    "    if curated_papers:\n",
    "        database.insert_papers(collection, curated_papers)\n",
    "\n",
    "print(f\"\\n--- Job finished at {datetime.now()} ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Existing Papers from the Database\n",
    "\n",
    "You can also use the package to directly query the results stored in your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the database collection\n",
    "collection = get_db_collection()\n",
    "\n",
    "if collection is not None:\n",
    "    # 2. Query the top 5 papers by relevance score\n",
    "    top_papers = get_top_papers(collection, limit=5)\n",
    "    total_papers = collection.count_documents({})\n",
    "    \n",
    "    print(f\"Total papers in database: {total_papers}\")\n",
    "    print(\"--- Top Papers ---\")\n",
    "    \n",
    "    # 3. Display the results\n",
    "    for i, paper in enumerate(top_papers, 1):\n",
    "        print(f\"{i}. {paper['title']}\")\n",
    "        print(f\"  Score: {paper.get('relevance_score', 'N/A')}/10\")\n",
    "        print(f\"  Keywords: {', '.join(paper.get('keywords', []))}\")\n",
    "        print(f\"  PDF: {paper['pdf_url']}\")\n",
    "        print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

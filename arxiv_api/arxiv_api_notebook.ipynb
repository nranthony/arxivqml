{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Quantum ML Paper Search & Curation\n",
    "\n",
    "This notebook searches arXiv for Quantum Machine Learning papers and uses an LLM to score and curate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import arxiv\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017/\")\n",
    "DB_NAME = \"arxiv_research\"\n",
    "COLLECTION_NAME = \"qml_papers\"\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize LLM and Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to MongoDB: arxiv_research.qml_papers\n",
      "✓ LLM initialized: models/gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759287983.545175 4111515 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# --- LLM Configuration ---\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    verbose=True,\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")\n",
    "\n",
    "# --- MongoDB Connection ---\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "print(f\"✓ Connected to MongoDB: {DB_NAME}.{COLLECTION_NAME}\")\n",
    "print(f\"✓ LLM initialized: {gemini_llm.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. arXiv Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(category: str, query: str) -> list:\n",
    "    \"\"\"Searches arXiv for papers in specific categories using a targeted query.\n",
    "\n",
    "    Args:\n",
    "        category: arXiv category (e.g., 'quant-ph', 'cs.LG')\n",
    "        query: Search query string\n",
    "\n",
    "    Returns:\n",
    "        List of paper dictionaries\n",
    "    \"\"\"\n",
    "    print(f\"Executing arXiv search in '{category}' for query: '{query}'...\")\n",
    "    search = arxiv.Search(\n",
    "        query=f'cat:{category} AND ({query})',\n",
    "        max_results=25,  # Limit results per search to keep it focused\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for result in search.results():\n",
    "        # Avoid duplicates\n",
    "        if collection.find_one({\"entry_id\": result.entry_id}):\n",
    "            continue\n",
    "\n",
    "        result_dict = {\n",
    "            \"entry_id\": result.entry_id,\n",
    "            \"title\": result.title,\n",
    "            \"authors\": [author.name for author in result.authors],\n",
    "            \"summary\": result.summary,\n",
    "            \"pdf_url\": result.pdf_url,\n",
    "            \"published\": result.published,\n",
    "            \"updated\": result.updated,\n",
    "            \"primary_category\": result.primary_category,\n",
    "            \"categories\": result.categories\n",
    "        }\n",
    "        results.append(result_dict)\n",
    "\n",
    "    print(f\"Found {len(results)} new papers.\")\n",
    "    return results\n",
    "\n",
    "print(\"✓ search_arxiv() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Paper Curation Function (LLM-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_papers(papers: list, guidance_context: str) -> list:\n",
    "    \"\"\"Curate and score papers using LLM.\n",
    "\n",
    "    Args:\n",
    "        papers: List of paper dictionaries from arXiv search\n",
    "        guidance_context: Context string to guide scoring\n",
    "\n",
    "    Returns:\n",
    "        List of papers with added relevance_score, score_justification, and keywords\n",
    "    \"\"\"\n",
    "    if not papers:\n",
    "        return []\n",
    "\n",
    "    curated_papers = []\n",
    "\n",
    "    for paper in papers:\n",
    "        prompt = f\"\"\"Analyze this research paper and provide a relevance score.\n",
    "\n",
    "GUIDANCE CONTEXT:\n",
    "{guidance_context}\n",
    "\n",
    "PAPER DETAILS:\n",
    "Title: {paper['title']}\n",
    "Authors: {', '.join(paper['authors'])}\n",
    "Abstract: {paper['summary']}\n",
    "Categories: {', '.join(paper['categories'])}\n",
    "\n",
    "TASK:\n",
    "1. Assign a relevance score from 1 (low) to 10 (high) based on the guidance context\n",
    "2. Write a brief (1-2 sentence) justification for your score\n",
    "3. Extract 3-5 keywords or key concepts from the abstract\n",
    "\n",
    "Respond ONLY with valid JSON in this exact format:\n",
    "{{\n",
    "    \"relevance_score\": <number 1-10>,\n",
    "    \"score_justification\": \"<your justification>\",\n",
    "    \"keywords\": [\"keyword1\", \"keyword2\", \"keyword3\"]\n",
    "}}\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = gemini_llm.invoke(prompt)\n",
    "            # Extract JSON from response\n",
    "            response_text = response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "            # Handle potential markdown formatting\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            elif \"```\" in response_text:\n",
    "                response_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "            curation_data = json.loads(response_text)\n",
    "\n",
    "            # Merge original paper data with curation data\n",
    "            curated_paper = {**paper, **curation_data}\n",
    "            curated_papers.append(curated_paper)\n",
    "\n",
    "            print(f\"Scored '{paper['title'][:60]}...' -> {curation_data['relevance_score']}/10\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error curating paper '{paper['title'][:60]}...': {e}\")\n",
    "            # Add paper without curation data\n",
    "            curated_papers.append(paper)\n",
    "\n",
    "    return curated_papers\n",
    "\n",
    "print(\"✓ curate_papers() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dynamic Context for the Curator ---\n",
    "guidance_context = (\n",
    "    \"My primary interest is in practical and near-term Quantum Machine Learning. \"\n",
    "    \"Score papers higher if they mention: \"\n",
    "    \"1. Specific algorithms like VQAs, QAOA, Quantum Kernels, or QNNs. \"\n",
    "    \"2. Benchmarking against classical methods or other quantum algorithms. \"\n",
    "    \"3. Implementations on actual quantum hardware or widely used simulators (like PennyLane). \"\n",
    "    \"4. Association with major quantum computing companies (IBM, Google Quantum AI, Xanadu, D-Wave, etc.). \"\n",
    "    \"Score lower if the paper is purely theoretical, highly abstract (e.g., quantum algebra), or lacks a clear connection to machine learning.\"\n",
    ")\n",
    "\n",
    "# --- Search Parameters ---\n",
    "search_terms = [\n",
    "    '\"Quantum Machine Learning\"', '\"QML\"', '\"Quantum AI\"',\n",
    "    '\"Variational Quantum Algorithm\"', '\"VQA\"', '\"Quantum Neural Network\"',\n",
    "    '\"Quantum Kernel Method\"', '\"Quantum Support Vector Machine\"',\n",
    "    '\"Quantum Annealing\" AND \"machine learning\"',\n",
    "    '\"parameterized quantum circuit\"'\n",
    "]\n",
    "query_string = \" OR \".join([f'ti:\"{term}\" OR abs:\"{term}\"' for term in search_terms])\n",
    "\n",
    "# arXiv categories to search\n",
    "categories = [\n",
    "    \"quant-ph\",  # Quantum Physics (Core)\n",
    "    \"cs.LG\",     # Machine Learning (CS)\n",
    "    \"cs.AI\",     # Artificial Intelligence (CS)\n",
    "    \"cond-mat.dis-nn\",  # Disordered Systems and Neural Networks (Physics)\n",
    "    \"math-ph\"    # Mathematical Physics\n",
    "]\n",
    "\n",
    "print(f\"✓ Search parameters defined\")\n",
    "print(f\"  Categories: {', '.join(categories)}\")\n",
    "print(f\"  Search terms: {len(search_terms)} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Search on Single Category\n",
    "\n",
    "Let's test with just one category first to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a single category\n",
    "test_category = \"quant-ph\"  # Change this to test different categories\n",
    "\n",
    "print(f\"\\n--- Testing search for category: {test_category} ---\")\n",
    "papers = search_arxiv(test_category, query_string)\n",
    "\n",
    "if papers:\n",
    "    print(f\"\\nFound {len(papers)} papers. Here are the first 3:\")\n",
    "    for i, paper in enumerate(papers[:3], 1):\n",
    "        print(f\"\\n{i}. {paper['title']}\")\n",
    "        print(f\"   Authors: {', '.join(paper['authors'][:3])}...\")\n",
    "        print(f\"   Published: {paper['published']}\")\n",
    "else:\n",
    "    print(\"No new papers found (they may already be in the database).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Curation on Sample Papers\n",
    "\n",
    "Test the LLM curation on a small batch first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test curation on first 2 papers (to avoid too many API calls)\n",
    "if papers:\n",
    "    print(f\"\\n--- Testing curation on first 2 papers ---\")\n",
    "    test_papers = papers[:2]\n",
    "    \n",
    "    curated = curate_papers(test_papers, guidance_context)\n",
    "    \n",
    "    print(f\"\\n--- Curation Results ---\")\n",
    "    for paper in curated:\n",
    "        print(f\"\\nTitle: {paper['title']}\")\n",
    "        if 'relevance_score' in paper:\n",
    "            print(f\"Score: {paper['relevance_score']}/10\")\n",
    "            print(f\"Justification: {paper['score_justification']}\")\n",
    "            print(f\"Keywords: {', '.join(paper['keywords'])}\")\n",
    "        else:\n",
    "            print(\"[Curation failed for this paper]\")\n",
    "else:\n",
    "    print(\"No papers to curate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Insert Test Papers to Database\n",
    "\n",
    "If curation worked, insert the test papers to MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert curated papers to database\n",
    "if 'curated' in locals() and curated:\n",
    "    print(f\"\\n--- Inserting {len(curated)} papers to database ---\")\n",
    "    \n",
    "    for paper in curated:\n",
    "        # Check for duplicates\n",
    "        if not collection.find_one({\"entry_id\": paper.get(\"entry_id\")}):\n",
    "            paper['timestamp_added'] = datetime.utcnow()\n",
    "            collection.insert_one(paper)\n",
    "            print(f\"✓ Inserted: {paper['title'][:60]}...\")\n",
    "        else:\n",
    "            print(f\"⊘ Already exists: {paper['title'][:60]}...\")\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "else:\n",
    "    print(\"No curated papers to insert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Full Search Job (All Categories)\n",
    "\n",
    "Once testing is successful, run the full job across all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_arxiv_search_job():\n",
    "    \"\"\"Runs the arXiv search and curation job.\"\"\"\n",
    "    print(f\"\\n--- Starting new arXiv search job at {datetime.now()} ---\")\n",
    "\n",
    "    for category in categories:\n",
    "        print(f\"\\n--- Processing category: {category} ---\")\n",
    "\n",
    "        # Step 1: Search arXiv\n",
    "        papers = search_arxiv(category, query_string)\n",
    "\n",
    "        if not papers:\n",
    "            print(f\"No new papers found for category '{category}'.\")\n",
    "            continue\n",
    "\n",
    "        # Step 2: Curate and score papers with LLM\n",
    "        curated_papers = curate_papers(papers, guidance_context)\n",
    "\n",
    "        # --- Database Insertion ---\n",
    "        try:\n",
    "            if curated_papers:\n",
    "                for paper in curated_papers:\n",
    "                    # Ensure we don't insert duplicates from a failed run\n",
    "                    if not collection.find_one({\"entry_id\": paper.get(\"entry_id\")}):\n",
    "                        paper['timestamp_added'] = datetime.utcnow()\n",
    "                        collection.insert_one(paper)\n",
    "                print(f\"Successfully inserted {len(curated_papers)} new papers into MongoDB for category '{category}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during database insertion for category '{category}': {e}\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# run_arxiv_search_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Query Database\n",
    "\n",
    "View papers that have been inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query papers from database\n",
    "print(f\"\\n--- Papers in Database ---\")\n",
    "total_count = collection.count_documents({})\n",
    "print(f\"Total papers: {total_count}\")\n",
    "\n",
    "if total_count > 0:\n",
    "    print(f\"\\nTop 5 papers by relevance score:\")\n",
    "    top_papers = collection.find(\n",
    "        {\"relevance_score\": {\"$exists\": True}}\n",
    "    ).sort(\"relevance_score\", -1).limit(5)\n",
    "    \n",
    "    for i, paper in enumerate(top_papers, 1):\n",
    "        print(f\"\\n{i}. {paper['title']}\")\n",
    "        print(f\"   Score: {paper.get('relevance_score', 'N/A')}/10\")\n",
    "        print(f\"   Keywords: {', '.join(paper.get('keywords', []))}\")\n",
    "        print(f\"   PDF: {paper['pdf_url']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
